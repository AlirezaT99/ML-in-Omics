{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "erawijantari_x_path = 'data/salma/erawijantari_x.csv'\n",
    "erawijantari_y_path = 'data/salma/erawijantari_y.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "erawijantari_x = pd.read_csv(erawijantari_x_path,)\n",
    "erawijantari_y = pd.read_csv(erawijantari_y_path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Oscillospiraceae;g__F23-B02;s__F23-B02 sp900556535',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Oscillospiraceae;g__CAG-103;s__CAG-103 sp018265835',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Oscillospiraceae;g__ER4;s__ER4 sp900556145',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Oscillospiraceae;g__F23-B02;s__F23-B02 sp900772725',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Oscillospiraceae;g__NSJ-62;s__NSJ-62 sp018919205',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Oscillospiraceae;g__ER4;s__ER4 sp017527825',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Oscillospiraceae;g__CAG-103;s__CAG-103 sp902760845',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Ruminococcaceae;g__Harryflintia;s__Harryflintia acetispora',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Oscillospiraceae;g__UBA2658;s__UBA2658 sp009929315',\n",
       "       'd__Bacteria;p__Deinococcota;c__Deinococci;o__Deinococcales;f__Thermaceae;g__Thermus;s__Thermus aquaticus',\n",
       "       'd__Bacteria;p__Bacteroidota;c__Bacteroidia;o__Chitinophagales;f__Chitinophagaceae;g__Filimonas;s__Filimonas zeae',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Lachnospirales;f__Lachnospiraceae;g__Mediterraneibacter;s__Mediterraneibacter gallistercoris',\n",
       "       'd__Bacteria;p__Verrucomicrobiota;c__Kiritimatiellae;o__RFP12;f__UBA1067;g__WRJS01;s__WRJS01 sp009777165',\n",
       "       'd__Bacteria;p__Proteobacteria;c__Alphaproteobacteria;o__SP197;f__SP197;g__MPMV01;s__MPMV01 sp002238685',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Ruminococcaceae;g__Harryflintia',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Oscillospirales;f__Oscillospiraceae;g__ER4',\n",
       "       'd__Bacteria;p__Firmicutes_A;c__Clostridia;o__Acetivibrionales;f__Acetivibrionaceae;g__Herbivorax',\n",
       "       'd__Bacteria;p__Proteobacteria;c__Alphaproteobacteria;o__SP197;f__SP197;g__MPMV01',\n",
       "       'C00019_SAM+', 'C00024_Acetyl CoA', 'C00041_Ala',\n",
       "       'C00043_UDP-N-acetylglucosamine', 'C00106_Uracil', 'C00148_Pro',\n",
       "       'C00170_5-Methylthioadenosine', 'C00179_Agmatine', 'C00214_Thymidine',\n",
       "       'C00253_Nicotinate', 'C00295_Orotate', 'C00327_Citrulline',\n",
       "       'C00385_Xanthine', 'C00407_Ile', 'C00429_Dihydrouracil',\n",
       "       'C00430_5-Aminolevulinate', 'C00864_Pantothenate',\n",
       "       'C02630_2-Hydroxyglutarate', 'C02989_Methionine sulfoxide',\n",
       "       'C05607_3-Phenyllactate', 'C07044_Hydroxyurea', 'C09815_Benzamide'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erawijantari_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erawijantari_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Study.Group'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erawijantari_y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erawijantari_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study.Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Gastrectomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Gastrectomy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Healthy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Study.Group\n",
       "0       Healthy\n",
       "1       Healthy\n",
       "2       Healthy\n",
       "3       Healthy\n",
       "4       Healthy\n",
       "..          ...\n",
       "91  Gastrectomy\n",
       "92      Healthy\n",
       "93      Healthy\n",
       "94  Gastrectomy\n",
       "95      Healthy\n",
       "\n",
       "[96 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "erawijantari_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming erawijantari_x and erawijantari_y are pandas DataFrame\n",
    "X = erawijantari_x.values\n",
    "y = erawijantari_y['Study.Group'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
    "\n",
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(40, 64)\n",
    "        # self.layer2 = nn.Linear(128, 64)\n",
    "        self.output_layer = nn.Linear(64, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        # x = torch.relu(self.layer2(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 281.31744384765625\n",
      "Epoch 2, Loss: 176.9986114501953\n",
      "Epoch 3, Loss: 167.2524871826172\n",
      "Epoch 4, Loss: 11.832443237304688\n",
      "Epoch 5, Loss: 90.53738403320312\n",
      "Epoch 6, Loss: 19.380109786987305\n",
      "Epoch 7, Loss: 52.23789596557617\n",
      "Epoch 8, Loss: 44.07072830200195\n",
      "Epoch 9, Loss: 148.75857543945312\n",
      "Epoch 10, Loss: 1.5894556781859137e-07\n",
      "Epoch 11, Loss: 26.7750301361084\n",
      "Epoch 12, Loss: 1.0794806480407715\n",
      "Epoch 13, Loss: 69.40055084228516\n",
      "Epoch 14, Loss: 2.8588428497314453\n",
      "Epoch 15, Loss: 18.98358726501465\n",
      "Epoch 16, Loss: 11.1744384765625\n",
      "Epoch 17, Loss: 44.356136322021484\n",
      "Epoch 18, Loss: 1.4741348028182983\n",
      "Epoch 19, Loss: 5.401528835296631\n",
      "Epoch 20, Loss: 21.573776245117188\n",
      "Epoch 21, Loss: 0.0\n",
      "Epoch 22, Loss: 0.28603458404541016\n",
      "Epoch 23, Loss: 18.76792335510254\n",
      "Epoch 24, Loss: 0.49804040789604187\n",
      "Epoch 25, Loss: 15.418559074401855\n",
      "Epoch 26, Loss: 0.004103260580450296\n",
      "Epoch 27, Loss: 11.00326919555664\n",
      "Epoch 28, Loss: 0.07292751222848892\n",
      "Epoch 29, Loss: 0.02639959193766117\n",
      "Epoch 30, Loss: 0.12382379919290543\n",
      "Epoch 31, Loss: 25.439918518066406\n",
      "Epoch 32, Loss: 2.6822047516361636e-07\n",
      "Epoch 33, Loss: 12.858819007873535\n",
      "Epoch 34, Loss: 2.012270450592041\n",
      "Epoch 35, Loss: 22.511802673339844\n",
      "Epoch 36, Loss: 0.42418262362480164\n",
      "Epoch 37, Loss: 14.953593254089355\n",
      "Epoch 38, Loss: 6.823209762573242\n",
      "Epoch 39, Loss: 1.89616858959198\n",
      "Epoch 40, Loss: 5.733993053436279\n",
      "Epoch 41, Loss: 1.4210814237594604\n",
      "Epoch 42, Loss: 0.14893533289432526\n",
      "Epoch 43, Loss: 8.752584457397461\n",
      "Epoch 44, Loss: 6.1500163078308105\n",
      "Epoch 45, Loss: 8.628618240356445\n",
      "Epoch 46, Loss: 19.48055076599121\n",
      "Epoch 47, Loss: 0.3009929656982422\n",
      "Epoch 48, Loss: 0.7652216553688049\n",
      "Epoch 49, Loss: 1.3128904104232788\n",
      "Epoch 50, Loss: 0.0008616168051958084\n",
      "Epoch 51, Loss: 1.1380590200424194\n",
      "Epoch 52, Loss: 3.0336537747643888e-05\n",
      "Epoch 53, Loss: 0.0022257380187511444\n",
      "Epoch 54, Loss: 1.28369140625\n",
      "Epoch 55, Loss: 0.0070156920701265335\n",
      "Epoch 56, Loss: 11.967070579528809\n",
      "Epoch 57, Loss: 7.996747626748402e-06\n",
      "Epoch 58, Loss: 0.4543086588382721\n",
      "Epoch 59, Loss: 0.5059060454368591\n",
      "Epoch 60, Loss: 1.4434503316879272\n",
      "Epoch 61, Loss: 1.4258208274841309\n",
      "Epoch 62, Loss: 0.23691673576831818\n",
      "Epoch 63, Loss: 0.6986007690429688\n",
      "Epoch 64, Loss: 0.06741418689489365\n",
      "Epoch 65, Loss: 1.059001088142395\n",
      "Epoch 66, Loss: 2.460315045027528e-05\n",
      "Epoch 67, Loss: 0.3308488428592682\n",
      "Epoch 68, Loss: 10.42467212677002\n",
      "Epoch 69, Loss: 0.0013870842522010207\n",
      "Epoch 70, Loss: 6.063376713427715e-05\n",
      "Epoch 71, Loss: 1.917271447382518e-06\n",
      "Epoch 72, Loss: 0.4556252062320709\n",
      "Epoch 73, Loss: 0.38213789463043213\n",
      "Epoch 74, Loss: 8.367059707641602\n",
      "Epoch 75, Loss: 3.836113929748535\n",
      "Epoch 76, Loss: 0.9393520951271057\n",
      "Epoch 77, Loss: 0.0001273863745154813\n",
      "Epoch 78, Loss: 0.4727117717266083\n",
      "Epoch 79, Loss: 0.03066558577120304\n",
      "Epoch 80, Loss: 8.198210716247559\n",
      "Epoch 81, Loss: 0.01204890850931406\n",
      "Epoch 82, Loss: 0.3650306165218353\n",
      "Epoch 83, Loss: 1.94890089915134e-05\n",
      "Epoch 84, Loss: 0.3913775384426117\n",
      "Epoch 85, Loss: 1.9218082427978516\n",
      "Epoch 86, Loss: 4.432765483856201\n",
      "Epoch 87, Loss: 2.2180798053741455\n",
      "Epoch 88, Loss: 0.0002068005851469934\n",
      "Epoch 89, Loss: 0.09122689813375473\n",
      "Epoch 90, Loss: 0.00015646456449758261\n",
      "Epoch 91, Loss: 0.019639311358332634\n",
      "Epoch 92, Loss: 0.0005018753581680357\n",
      "Epoch 93, Loss: 0.07324714213609695\n",
      "Epoch 94, Loss: 0.0\n",
      "Epoch 95, Loss: 0.04855319485068321\n",
      "Epoch 96, Loss: 3.049715132874553e-06\n",
      "Epoch 97, Loss: 0.22538860142230988\n",
      "Epoch 98, Loss: 3.973642037635727e-08\n",
      "Epoch 99, Loss: 0.02135971374809742\n",
      "Epoch 100, Loss: 0.038067568093538284\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Optionally, after each epoch, evaluate your model on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # During testing, gradient computation is unnecessary\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test set: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.005405260715633631\n",
      "Epoch 2, Loss: 8.222163887694478e-05\n",
      "Epoch 3, Loss: 1.5993764463928528e-06\n",
      "Epoch 4, Loss: 3.973642037635727e-08\n",
      "Epoch 5, Loss: 0.0001193355637951754\n",
      "Epoch 6, Loss: 0.0002158268471248448\n",
      "Epoch 7, Loss: 0.00011978172551607713\n",
      "Epoch 8, Loss: 0.00015553459525108337\n",
      "Epoch 9, Loss: 0.00010642511915648356\n",
      "Epoch 10, Loss: 1.4801688621446374e-06\n",
      "Epoch 11, Loss: 0.0006191019783727825\n",
      "Epoch 12, Loss: 1.336030982201919e-05\n",
      "Epoch 13, Loss: 4.4860313209937885e-05\n",
      "Epoch 14, Loss: 1.7670918168732896e-05\n",
      "Epoch 15, Loss: 0.0007006505038589239\n",
      "Epoch 16, Loss: 1.4056113286642358e-05\n",
      "Epoch 17, Loss: 2.524867704778444e-05\n",
      "Epoch 18, Loss: 0.001168683054856956\n",
      "Epoch 19, Loss: 0.00015856580284889787\n",
      "Epoch 20, Loss: 9.983417839976028e-06\n",
      "Epoch 21, Loss: 6.953872144777051e-08\n",
      "Epoch 22, Loss: 1.797894037736114e-05\n",
      "Epoch 23, Loss: 0.0006497439462691545\n",
      "Epoch 24, Loss: 0.00011592932423809543\n",
      "Epoch 25, Loss: 0.002313216682523489\n",
      "Epoch 26, Loss: 0.00015643447113689035\n",
      "Epoch 27, Loss: 0.0007682314026169479\n",
      "Epoch 28, Loss: 0.0009806746384128928\n",
      "Epoch 29, Loss: 0.0007922148797661066\n",
      "Epoch 30, Loss: 1.3986174053570721e-05\n",
      "Epoch 31, Loss: 0.00012880541908089072\n",
      "Epoch 32, Loss: 0.0008494589128531516\n",
      "Epoch 33, Loss: 5.344379587768344e-06\n",
      "Epoch 34, Loss: 0.000662701902911067\n",
      "Epoch 35, Loss: 0.0001915453904075548\n",
      "Epoch 36, Loss: 1.0639053471095394e-05\n",
      "Epoch 37, Loss: 1.2108797818655148e-05\n",
      "Epoch 38, Loss: 0.0009121944312937558\n",
      "Epoch 39, Loss: 0.0001274167443625629\n",
      "Epoch 40, Loss: 2.094858245982323e-05\n",
      "Epoch 41, Loss: 0.0008180305012501776\n",
      "Epoch 42, Loss: 0.0008865543641149998\n",
      "Epoch 43, Loss: 0.001173295546323061\n",
      "Epoch 44, Loss: 2.570684409874957e-05\n",
      "Epoch 45, Loss: 2.9802317058624794e-08\n",
      "Epoch 46, Loss: 0.0013936003670096397\n",
      "Epoch 47, Loss: 0.0006467138882726431\n",
      "Epoch 48, Loss: 7.947281943643247e-08\n",
      "Epoch 49, Loss: 0.0009787852177396417\n",
      "Epoch 50, Loss: 0.00024502488668076694\n",
      "Epoch 51, Loss: 0.00021258606284391135\n",
      "Epoch 52, Loss: 0.0007192298653535545\n",
      "Epoch 53, Loss: 0.0009189378470182419\n",
      "Epoch 54, Loss: 1.8377899095867178e-06\n",
      "Epoch 55, Loss: 0.0006825117743574083\n",
      "Epoch 56, Loss: 0.00033885581069625914\n",
      "Epoch 57, Loss: 1.718582893772691e-06\n",
      "Epoch 58, Loss: 2.2418267690227367e-05\n",
      "Epoch 59, Loss: 0.0001248972985194996\n",
      "Epoch 60, Loss: 0.0006569523829966784\n",
      "Epoch 61, Loss: 0.0008947726455517113\n",
      "Epoch 62, Loss: 0.0002130628126906231\n",
      "Epoch 63, Loss: 0.0008884063572622836\n",
      "Epoch 64, Loss: 5.87090517001343e-06\n",
      "Epoch 65, Loss: 7.440323770424584e-06\n",
      "Epoch 66, Loss: 0.000640481652226299\n",
      "Epoch 67, Loss: 8.642635407341004e-07\n",
      "Epoch 68, Loss: 0.0006751588080078363\n",
      "Epoch 69, Loss: 0.0007714322418905795\n",
      "Epoch 70, Loss: 6.109304649726255e-06\n",
      "Epoch 71, Loss: 7.947248263917572e-07\n",
      "Epoch 72, Loss: 0.0006194194429554045\n",
      "Epoch 73, Loss: 0.0\n",
      "Epoch 74, Loss: 0.0006351876654662192\n",
      "Epoch 75, Loss: 1.4603010640712455e-06\n",
      "Epoch 76, Loss: 0.0007066534017212689\n",
      "Epoch 77, Loss: 0.00019326953042764217\n",
      "Epoch 78, Loss: 2.3282880647457205e-05\n",
      "Epoch 79, Loss: 2.3543504994449904e-06\n",
      "Epoch 80, Loss: 0.0002104866289300844\n",
      "Epoch 81, Loss: 0.0006712802569381893\n",
      "Epoch 82, Loss: 0.0009333823691122234\n",
      "Epoch 83, Loss: 0.0003183450608048588\n",
      "Epoch 84, Loss: 0.00019286904716864228\n",
      "Epoch 85, Loss: 0.0008461424149572849\n",
      "Epoch 86, Loss: 1.3609616189569351e-06\n",
      "Epoch 87, Loss: 0.0005493003991432488\n",
      "Epoch 88, Loss: 0.00019252423953730613\n",
      "Epoch 89, Loss: 0.0011710618855431676\n",
      "Epoch 90, Loss: 5.2152431635477114e-06\n",
      "Epoch 91, Loss: 1.9766532204812393e-05\n",
      "Epoch 92, Loss: 0.0\n",
      "Epoch 93, Loss: 9.01968542166287e-06\n",
      "Epoch 94, Loss: 9.230879368260503e-05\n",
      "Epoch 95, Loss: 0.0001653480139793828\n",
      "Epoch 96, Loss: 0.00017363576625939459\n",
      "Epoch 97, Loss: 1.5118690498638898e-05\n",
      "Epoch 98, Loss: 9.351482731290162e-05\n",
      "Epoch 99, Loss: 9.464773029321805e-05\n",
      "Epoch 100, Loss: 5.831161615788005e-06\n",
      "Accuracy of the model on the test set: 85.00%\n"
     ]
    }
   ],
   "source": [
    "# Training loop as defined earlier\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # Make sure the model is in training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Testing loop\n",
    "test_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.6231\n",
      "Epoch 2/50, Loss: 0.6598\n",
      "Epoch 3/50, Loss: 0.6264\n",
      "Epoch 4/50, Loss: 0.6233\n",
      "Epoch 5/50, Loss: 0.6011\n",
      "Epoch 6/50, Loss: 0.5481\n",
      "Epoch 7/50, Loss: 0.6931\n",
      "Epoch 8/50, Loss: 0.4518\n",
      "Epoch 9/50, Loss: 0.6117\n",
      "Epoch 10/50, Loss: 0.6006\n",
      "Epoch 11/50, Loss: 0.2609\n",
      "Epoch 12/50, Loss: 0.2892\n",
      "Epoch 13/50, Loss: 0.1310\n",
      "Epoch 14/50, Loss: 0.3257\n",
      "Epoch 15/50, Loss: 0.3517\n",
      "Epoch 16/50, Loss: 0.2997\n",
      "Epoch 17/50, Loss: 0.0098\n",
      "Epoch 18/50, Loss: 0.1336\n",
      "Epoch 19/50, Loss: 0.2205\n",
      "Epoch 20/50, Loss: 0.0935\n",
      "Epoch 21/50, Loss: 0.1963\n",
      "Epoch 22/50, Loss: 0.1043\n",
      "Epoch 23/50, Loss: 0.0640\n",
      "Epoch 24/50, Loss: 0.1425\n",
      "Epoch 25/50, Loss: 0.0194\n",
      "Epoch 26/50, Loss: 0.0202\n",
      "Epoch 27/50, Loss: 0.1559\n",
      "Epoch 28/50, Loss: 0.0994\n",
      "Epoch 29/50, Loss: 0.0045\n",
      "Epoch 30/50, Loss: 0.0377\n",
      "Epoch 31/50, Loss: 0.0019\n",
      "Epoch 32/50, Loss: 0.0040\n",
      "Epoch 33/50, Loss: 0.0367\n",
      "Epoch 34/50, Loss: 0.0611\n",
      "Epoch 35/50, Loss: 0.0001\n",
      "Epoch 36/50, Loss: 0.0450\n",
      "Epoch 37/50, Loss: 0.0621\n",
      "Epoch 38/50, Loss: 0.0010\n",
      "Epoch 39/50, Loss: 0.0001\n",
      "Epoch 40/50, Loss: 0.0089\n",
      "Epoch 41/50, Loss: 0.0087\n",
      "Epoch 42/50, Loss: 0.0667\n",
      "Epoch 43/50, Loss: 0.0082\n",
      "Epoch 44/50, Loss: 0.0202\n",
      "Epoch 45/50, Loss: 0.3216\n",
      "Epoch 46/50, Loss: 0.0006\n",
      "Epoch 47/50, Loss: 0.0147\n",
      "Epoch 48/50, Loss: 0.0250\n",
      "Epoch 49/50, Loss: 0.0393\n",
      "Epoch 50/50, Loss: 0.0020\n",
      "Test Accuracy: 0.9655\n"
     ]
    }
   ],
   "source": [
    "# Assuming erawijantari_x and erawijantari_y are loaded as described previously\n",
    "\n",
    "# Preprocessing\n",
    "# Convert categorical output to numeric\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(erawijantari_y['Study.Group'])\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(erawijantari_x)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=16, shuffle=True)\n",
    "\n",
    "# Model Design\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(X_train.shape[1], 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.layer4(x))\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    accuracy = (y_pred == y_test).float().mean()\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "kim_adenomas_X_path = 'data/mohammad/kim_adenomas_X.csv'\n",
    "kim_adenomas_y_path = 'data/mohammad/kim_adenomas_y.csv'\n",
    "kim_adenomas_X = pd.read_csv(kim_adenomas_X_path,)\n",
    "kim_adenomas_y = pd.read_csv(kim_adenomas_y_path,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.7061\n",
      "Epoch 2/50, Loss: 0.6890\n",
      "Epoch 3/50, Loss: 0.6821\n",
      "Epoch 4/50, Loss: 0.6846\n",
      "Epoch 5/50, Loss: 0.6452\n",
      "Epoch 6/50, Loss: 0.7930\n",
      "Epoch 7/50, Loss: 0.6944\n",
      "Epoch 8/50, Loss: 0.6287\n",
      "Epoch 9/50, Loss: 0.6429\n",
      "Epoch 10/50, Loss: 0.5631\n",
      "Epoch 11/50, Loss: 0.5885\n",
      "Epoch 12/50, Loss: 0.6495\n",
      "Epoch 13/50, Loss: 0.6983\n",
      "Epoch 14/50, Loss: 0.5042\n",
      "Epoch 15/50, Loss: 0.5725\n",
      "Epoch 16/50, Loss: 0.3359\n",
      "Epoch 17/50, Loss: 0.5526\n",
      "Epoch 18/50, Loss: 0.6517\n",
      "Epoch 19/50, Loss: 0.4777\n",
      "Epoch 20/50, Loss: 0.5509\n",
      "Epoch 21/50, Loss: 0.3756\n",
      "Epoch 22/50, Loss: 0.4308\n",
      "Epoch 23/50, Loss: 0.4109\n",
      "Epoch 24/50, Loss: 0.4719\n",
      "Epoch 25/50, Loss: 0.3515\n",
      "Epoch 26/50, Loss: 0.4473\n",
      "Epoch 27/50, Loss: 0.6464\n",
      "Epoch 28/50, Loss: 0.5940\n",
      "Epoch 29/50, Loss: 0.3717\n",
      "Epoch 30/50, Loss: 0.6188\n",
      "Epoch 31/50, Loss: 0.4659\n",
      "Epoch 32/50, Loss: 0.8280\n",
      "Epoch 33/50, Loss: 0.5914\n",
      "Epoch 34/50, Loss: 0.3825\n",
      "Epoch 35/50, Loss: 0.9047\n",
      "Epoch 36/50, Loss: 0.2476\n",
      "Epoch 37/50, Loss: 0.4669\n",
      "Epoch 38/50, Loss: 0.3720\n",
      "Epoch 39/50, Loss: 0.4119\n",
      "Epoch 40/50, Loss: 0.9061\n",
      "Epoch 41/50, Loss: 0.6760\n",
      "Epoch 42/50, Loss: 0.4035\n",
      "Epoch 43/50, Loss: 0.4184\n",
      "Epoch 44/50, Loss: 0.6412\n",
      "Epoch 45/50, Loss: 0.3151\n",
      "Epoch 46/50, Loss: 0.7505\n",
      "Epoch 47/50, Loss: 0.4216\n",
      "Epoch 48/50, Loss: 0.4800\n",
      "Epoch 49/50, Loss: 0.2857\n",
      "Epoch 50/50, Loss: 0.3056\n",
      "Test Accuracy: 0.5139\n"
     ]
    }
   ],
   "source": [
    "# Assuming erawijantari_x and erawijantari_y are loaded as described previously\n",
    "\n",
    "# Preprocessing\n",
    "# Convert categorical output to numeric\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(kim_adenomas_y['Study.Group'])\n",
    "\n",
    "# Scale the input features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(kim_adenomas_X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert arrays to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=16, shuffle=True)\n",
    "\n",
    "# Model Design\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(X_train.shape[1], 128)\n",
    "        self.layer2 = nn.Linear(128, 64)\n",
    "        self.layer3 = nn.Linear(64, 32)\n",
    "        self.layer4 = nn.Linear(32, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.layer3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.layer4(x))\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    y_pred = y_pred.round()\n",
    "    accuracy = (y_pred == y_test).float().mean()\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
